{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what if somebody decides to break it be careful that you keep adequate coverage but look for places to save money maybe it's taking longer to get things squared away then the bankers expected iring the wife for one company may wen her taxated retirement and con the booss just helpful but in adequate new self to seeing rags or heardly tossed on the to naked bone what i discussion can insue when the title of this type of song is in question thereis no dying or waxing or gasing neede nigborweight may be personal asknown back how clays leather hard n lace work on a slat surface and smooth out this sipliss cind of separate system uses eat single self contained unit te old shop atage still holds a good menchanic as usually a bad boss so figures would go hir in lader years some maye beautiful chairs cabinets chest dowhouses et ceter\n"
     ]
    }
   ],
   "source": [
    "# Speech to Text Conversion\n",
    "\n",
    "from deepspeech import Model\n",
    "import scipy.io.wavfile as wav\n",
    "import sys\n",
    "\n",
    "#input graph\n",
    "input_graph = \"deepspeech-0.5.1-models/output_graph.pbmm\"\n",
    "alphabet = \"deepspeech-0.5.1-models/alphabet.txt\"\n",
    "audio_file = \"male.wav\"\n",
    "\n",
    "#deepSpeech = Model(sys.argv[1], 26, 9, sys.argv[2], 500)\n",
    "deepSpeech = Model(input_graph, 26, 9, alphabet, 500)\n",
    "\n",
    "fs, audio = wav.read(audio_file)\n",
    "\n",
    "text_data = deepSpeech.stt(audio, fs)\n",
    "\n",
    "print(text_data)\n",
    "\n",
    "with open('out_text.txt', 'a') as f:\n",
    "    f.write(text_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-42424eb333fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what if somebody decides to break it be careful that you keep adequate coverage but look for places to save money maybe it s taking longer to get things squared away then the bankers expected iring the wife for one company may wen her taxated retirement and con the booss just helpful but in adequate new self to seeing rags or heardly tossed on the to naked bone what i discussion can insue when the title of this type of song is in question thereis no dying or waxing or gasing neede nigborweight may be personal asknown back how clays leather hard n lace work on a slat surface and smooth out this sipliss cind of separate system uses eat single self contained unit te old shop atage still holds a good menchanic as usually a bad boss so figures would go hir in lader years some maye beautiful chairs cabinets chest dowhouses et ceter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dwith\\appdata\\local\\continuum\\miniconda3\\envs\\tf-speech\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['come', 'vis', 'viser', 'visest'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['decides',\n",
       " 'break',\n",
       " 'careful',\n",
       " 'keep',\n",
       " 'adequate',\n",
       " 'coverage',\n",
       " 'look',\n",
       " 'places',\n",
       " 'save',\n",
       " 'money']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keyword detection\n",
    "import pandas as pd\n",
    "\n",
    "# pre-processing\n",
    "import re\n",
    "def pre_process(text):\n",
    "    #convert to lower case\n",
    "    text = text.lower()\n",
    "    #remove tags\n",
    "    text = re.sub(\"&lt;/?.*?&gt;\",\"&lt;&gt;\",text)\n",
    "    #remove special characters\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# vocabulary\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "def get_stop_words(stop_file_path):\n",
    "    # load stop words from file\n",
    "    with open (stop_file_path, 'r', encoding='utf-8') as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "        return frozenset(stop_set)\n",
    "    \n",
    "# load stop works\n",
    "stopwords = get_stop_words(\"stopwords.txt\")\n",
    "\n",
    "cv = CountVectorizer(stop_words=stopwords, max_features=10000)\n",
    "#cv = CountVectorizer(max_df=0.85, stop_words=stopwords,max_features=1000)\n",
    "#convert string to list\n",
    "text_data = pre_process(text_data)\n",
    "print(text_data)\n",
    "word_count_vector = cv.fit_transform([text_data])\n",
    "\n",
    "#print a few words\n",
    "list(cv.vocabulary_.keys())[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Document ##########\n",
      "what if somebody decides to break it be careful that you keep adequate coverage but look for places to save money maybe it s taking longer to get things squared away then the bankers expected iring the wife for one company may wen her taxated retirement and con the booss just helpful but in adequate new self to seeing rags or heardly tossed on the to naked bone what i discussion can insue when the title of this type of song is in question thereis no dying or waxing or gasing neede nigborweight may be personal asknown back how clays leather hard n lace work on a slat surface and smooth out this sipliss cind of separate system uses eat single self contained unit te old shop atage still holds a good menchanic as usually a bad boss so figures would go hir in lader years some maye beautiful chairs cabinets chest dowhouses et ceter\n",
      "######### key works ##########\n",
      "self 0.203\n",
      "may 0.203\n",
      "adequate 0.203\n",
      "years 0.102\n",
      "work 0.102\n",
      "wife 0.102\n",
      "wen 0.102\n",
      "waxing 0.102\n",
      "uses 0.102\n",
      "unit 0.102\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF transform\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#function to sort keywords\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse = True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    sorted_items = sorted_items[:topn]\n",
    "    \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    for idx, score in sorted_items:\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]] = score_vals[idx]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "tfidf_trans = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf_trans.fit(word_count_vector)\n",
    "\n",
    "feature_names = cv.get_feature_names()\n",
    "\n",
    "tf_idf_vector = tfidf_trans.transform(cv.transform([text_data]))\n",
    "\n",
    "sorted_items = sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "keywords = extract_topn_from_vector(feature_names, sorted_items, 10)\n",
    "\n",
    "\n",
    "print(\"######### Document ##########\")\n",
    "print(text_data)\n",
    "\n",
    "print(\"######### key works ##########\")\n",
    "for k in keywords:\n",
    "    print(k, keywords[k])\n",
    "    \n",
    "with open('keywords.txt', 'w') as f:\n",
    "    for k in keywords:\n",
    "        f.write(k + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
